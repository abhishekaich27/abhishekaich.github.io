{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#  [Conditional Generative Adversarial Nets](https://arxiv.org/pdf/1411.1784.pdf)\n",
    "\n",
    "* * *\n",
    "\n",
    "## Idea: \n",
    "<p style='text-align: justify;'>\n",
    "The generative model (GANs) introduced in <a href=\"https://arxiv.org/pdf/1406.2661.pdf\">[1]</a> has no control on modes of the data being generated. This paper proposes a solution to the same by conditioning the model on additional information. This conditioning can be based on class labels, on some part of data, and as more recent works suggest, even on data from different modalities.\n",
    "</p>\n",
    "\n",
    "* * *\n",
    "\n",
    "## Details:\n",
    "\n",
    "<script type=\"text/x-mathjax-config\">\n",
    "  MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\\\(','\\\\)']]}});\n",
    "</script>\n",
    "<script type=\"text/javascript\"\n",
    "  src=\"http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML\">\n",
    "</script>\n",
    "<p style='text-align: justify;'>\n",
    "GANs can be converted into a conditional GAN when both the generator $\\mathcal{G}$, and discriminator $\\mathcal{D}$ networks are conditioned on some extra information $\\textbf{y}$. This conditioning can be performed by feeding $\\textbf{y}$ into the both $\\mathcal{G}$ and $\\mathcal{D}$ as additional input layer. Define the prior input noise as $p_\\textbf{z}(\\textbf{z})$, and input as $\\textbf{x}$. $p_\\textbf{z}(\\textbf{z})$ and $\\textbf{y}$ are combined in joint hidden representation. The objective to train this network is as follows and obtain a generator $\\mathcal{G}^\\star$ such that the discriminator selects the real image and generated image with equal probability:\n",
    "    <br>\n",
    "$$\n",
    "    \\begin{align}\n",
    "    \\mathcal{G}^\\star = \\mathbb{E}_{\\textbf{X}, \\textbf{V}}\\big{[}\\log \\mathcal{D}(\\textbf{X}\\vert \\textbf{V})\\big{]} + \\mathbb{E}_{\\textbf{z},  \\textbf{V}}\\big{[}\\log (1 - \\mathcal{D}(\\mathcal{G}(\\textbf{z}\\vert \\textbf{V}))\\big{]}\n",
    "\\end{align}\n",
    "$$\n",
    "</p>\n",
    "\n",
    "* * *\n",
    "\n",
    "## Experimental Results:\n",
    "\n",
    "<p style='text-align: justify;'>\n",
    "The authors trained a conditional adversarial net on MNIST images conditioned on their class labels, encoded\n",
    "as one-hot vectors for a unimodal demonstration. The results are comparable with some other network based, but non-conditional adversarial nets. \n",
    "    \n",
    "For the multi-modal case, the authors use MIR Flickr 25,000 dataset and extracted the image and tags features using the convolutional model and language model.\n",
    "</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
